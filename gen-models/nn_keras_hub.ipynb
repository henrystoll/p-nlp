{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from comet_ml import Experiment\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_50.csv')\n",
    "X = df['text_tokenized']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)  # 0.8 * 0.25 = 0.2\n",
    "\n",
    "class_names = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embed_model=\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "embedding_dim = 20\n",
    "activation = 'relu'\n",
    "kernel_initializer = 'he_normal'\n",
    "l2_lambda = 1e-3\n",
    "dropout=0.5\n",
    "filters = 64\n",
    "kernel_sizes = [1, 2, 3]\n",
    "n_convs_parallel = len(kernel_sizes)\n",
    "padding='same'\n",
    "pool_size = 2\n",
    "strides = 1\n",
    "epochs = 200\n",
    "optimizer = 'nadam'\n",
    "\n",
    "for embed_model in tfhub_embedding_models:\n",
    "    def make_model():\n",
    "        regularizers = keras.regularizers.l2(l2=l2_lambda)\n",
    "        model = keras.Sequential([\n",
    "            hub.KerasLayer(embed_model, dtype=tf.string, input_shape=[], output_shape=[embedding_dim]),\n",
    "            keras.layers.Dense(128, activation=activation, kernel_initializer=kernel_initializer, kernel_regularizer=regularizers),\n",
    "            keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
    "        ])\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    project_name = 'nlp_kerashub'\n",
    "    experiment = Experiment(\n",
    "        project_name=project_name,\n",
    "        auto_param_logging=True,\n",
    "        # auto_histogram_weight_logging=True,\n",
    "        auto_histogram_gradient_logging=True,\n",
    "        auto_histogram_activation_logging=True,\n",
    "        api_key=\"HeH9EtfDC2KUlCOjeQaU1CuOM\",\n",
    "        workspace=\"henrystoll\",\n",
    "    )\n",
    "    params = {\n",
    "        'batch_size': batch_size,\n",
    "        'embed_model': embed_model,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'pool_size': pool_size,\n",
    "        'padding': padding,\n",
    "        'strides': strides,\n",
    "        'n_convs_parallel': n_convs_parallel,\n",
    "        'activation': activation,\n",
    "        'kernel_initializer': kernel_initializer,\n",
    "        'l2_lambda': l2_lambda,\n",
    "        'dropout': dropout,\n",
    "        'optimizer': optimizer,\n",
    "        'epochs': epochs,\n",
    "    }\n",
    "\n",
    "    experiment.log_parameters(params)\n",
    "\n",
    "    model = make_model()\n",
    "    # keras.utils.plot_model(model, \"model.png\", show_shapes=True)\n",
    "    # experiment.log_asset(\"model.png\")\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    with experiment.train():\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "    with experiment.test():\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('acc : {:.3f}'.format(accuracy))\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        experiment.log_metrics(metrics)\n",
    "\n",
    "    y_predicted = model.predict(X_test)\n",
    "    y_predicted = y_predicted.argmax(axis=1)\n",
    "    experiment.log_confusion_matrix(y_test.to_numpy(), y_predicted)\n",
    "\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/henrystoll/nlp-kerashub/ba9da4a43afd4daa831f18aaddf31ae9\n",
      "\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 403,224\n",
      "Trainable params: 3,204\n",
      "Non-trainable params: 400,020\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 5s 70ms/step - loss: 2.1347 - acc: 0.3977 - val_loss: 1.6408 - val_acc: 0.4148\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.4321 - acc: 0.4930 - val_loss: 1.4079 - val_acc: 0.5137\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 1.3118 - acc: 0.5298 - val_loss: 1.3009 - val_acc: 0.5381\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 1.2125 - acc: 0.5674 - val_loss: 1.2466 - val_acc: 0.5588\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.1667 - acc: 0.5901 - val_loss: 1.1631 - val_acc: 0.5753\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1281 - acc: 0.6092 - val_loss: 1.2388 - val_acc: 0.5339\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 1.1180 - acc: 0.6104 - val_loss: 1.1839 - val_acc: 0.5790\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 1.0661 - acc: 0.6384 - val_loss: 1.1593 - val_acc: 0.5976\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 1.0577 - acc: 0.6443 - val_loss: 1.1473 - val_acc: 0.5614\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 1.0392 - acc: 0.6453 - val_loss: 1.0516 - val_acc: 0.6447\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 1.0206 - acc: 0.6548 - val_loss: 1.6739 - val_acc: 0.3951\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.0172 - acc: 0.6590 - val_loss: 1.2011 - val_acc: 0.5401\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9798 - acc: 0.6762 - val_loss: 1.1787 - val_acc: 0.5748\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9671 - acc: 0.6798 - val_loss: 1.1125 - val_acc: 0.5961\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9740 - acc: 0.6728 - val_loss: 1.2417 - val_acc: 0.5158\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9570 - acc: 0.6900 - val_loss: 1.0225 - val_acc: 0.6603\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.9426 - acc: 0.6918 - val_loss: 1.0057 - val_acc: 0.6618\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9394 - acc: 0.6902 - val_loss: 0.9916 - val_acc: 0.6655.9374 - acc: 0.69\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9364 - acc: 0.6918 - val_loss: 1.1769 - val_acc: 0.5520\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9167 - acc: 0.7101 - val_loss: 0.9566 - val_acc: 0.6820\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8979 - acc: 0.7144 - val_loss: 1.0630 - val_acc: 0.6100\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9039 - acc: 0.7094 - val_loss: 1.0341 - val_acc: 0.6380\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8986 - acc: 0.7142 - val_loss: 0.9494 - val_acc: 0.6712\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8830 - acc: 0.7234 - val_loss: 0.9447 - val_acc: 0.6882\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8899 - acc: 0.7144 - val_loss: 1.0152 - val_acc: 0.6473\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8784 - acc: 0.7178 - val_loss: 0.9480 - val_acc: 0.6898\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.8780 - acc: 0.7211 - val_loss: 0.9236 - val_acc: 0.6981\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.8589 - acc: 0.7322 - val_loss: 0.9329 - val_acc: 0.6846\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8621 - acc: 0.7303 - val_loss: 1.0283 - val_acc: 0.6256\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8449 - acc: 0.7372 - val_loss: 0.9229 - val_acc: 0.6914\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8502 - acc: 0.7315 - val_loss: 1.1111 - val_acc: 0.5748\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8527 - acc: 0.7280 - val_loss: 1.0312 - val_acc: 0.6256\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8477 - acc: 0.7301 - val_loss: 1.0532 - val_acc: 0.6002\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8328 - acc: 0.7382 - val_loss: 0.9370 - val_acc: 0.6769\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8231 - acc: 0.7446 - val_loss: 0.9596 - val_acc: 0.6737\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.8176 - acc: 0.7449 - val_loss: 0.9212 - val_acc: 0.6903\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.8222 - acc: 0.7443 - val_loss: 0.9870 - val_acc: 0.6484\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 0.8752 - acc: 0.7255\n",
      "acc : 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/henrystoll/nlp-kerashub/ba9da4a43afd4daa831f18aaddf31ae9\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     test_accuracy             : 0.7255308032035828\n",
      "COMET INFO:     test_loss                 : 0.8751965761184692\n",
      "COMET INFO:     train_acc [37]            : (0.39768606424331665, 0.7449490427970886)\n",
      "COMET INFO:     train_batch_acc [185]     : (0.3794642984867096, 0.7535511255264282)\n",
      "COMET INFO:     train_batch_loss [185]    : (0.7758073806762695, 4.043598175048828)\n",
      "COMET INFO:     train_epoch_duration [37] : (2.039828163004131, 4.569479643992963)\n",
      "COMET INFO:     train_loss [37]           : (0.8176402449607849, 2.1347265243530273)\n",
      "COMET INFO:     train_val_acc [37]        : (0.39513206481933594, 0.6980838775634766)\n",
      "COMET INFO:     train_val_loss [37]       : (0.9212316870689392, 1.6739304065704346)\n",
      "COMET INFO:     validate_batch_acc [74]   : (0.40553978085517883, 0.7734375)\n",
      "COMET INFO:     validate_batch_loss [74]  : (0.7448891997337341, 1.6546958684921265)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     train_trainable_params : 403224\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Nadam_beta_1        : 0.9\n",
      "COMET INFO:     Nadam_beta_2        : 0.999\n",
      "COMET INFO:     Nadam_decay         : 0.004\n",
      "COMET INFO:     Nadam_epsilon       : 1e-07\n",
      "COMET INFO:     Nadam_learning_rate : 0.001\n",
      "COMET INFO:     Optimizer           : Nadam\n",
      "COMET INFO:     activation          : relu\n",
      "COMET INFO:     batch_size          : 128\n",
      "COMET INFO:     dropout             : 0.5\n",
      "COMET INFO:     embed_model         : https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\n",
      "COMET INFO:     embedding_dim       : 20\n",
      "COMET INFO:     epochs              : 200\n",
      "COMET INFO:     filters             : 64\n",
      "COMET INFO:     kernel_initializer  : he_normal\n",
      "COMET INFO:     kernel_sizes        : [1, 2, 3]\n",
      "COMET INFO:     l2_lambda           : 0.001\n",
      "COMET INFO:     n_convs_parallel    : 3\n",
      "COMET INFO:     optimizer           : nadam\n",
      "COMET INFO:     padding             : same\n",
      "COMET INFO:     pool_size           : 2\n",
      "COMET INFO:     strides             : 1\n",
      "COMET INFO:     train_Nadam_name    : Nadam\n",
      "COMET INFO:     train_steps         : 46\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     confusion-matrix    : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     histogram3d         : 38\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
