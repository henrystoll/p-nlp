{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from comet_ml import Experiment\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/tweets_50_shuffled_train.csv')\n",
    "test_df = pd.read_csv('../data/tweets_50_shuffled_test.csv')\n",
    "X_train = train_df['text_tokenized']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_tokenized']\n",
    "y_test = test_df['label']\n",
    "\n",
    "class_names = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/henrystoll/nlp-split/4f1d035fe2c148d59521d907d51ca5fb\n",
      "\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 403,095\n",
      "Trainable params: 3,075\n",
      "Non-trainable params: 400,020\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 6s 76ms/step - loss: 1.9700 - acc: 0.4326 - val_loss: 1.8170 - val_acc: 0.4313\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.3057 - acc: 0.5388 - val_loss: 1.5130 - val_acc: 0.4281\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 4s 67ms/step - loss: 1.1699 - acc: 0.5833 - val_loss: 1.3491 - val_acc: 0.4524\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 4s 70ms/step - loss: 1.1200 - acc: 0.5942 - val_loss: 1.3009 - val_acc: 0.4793\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 1.0618 - acc: 0.6249 - val_loss: 1.2335 - val_acc: 0.6020\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.0422 - acc: 0.6299 - val_loss: 1.7315 - val_acc: 0.3976\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.0312 - acc: 0.6304 - val_loss: 2.6319 - val_acc: 0.2093\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.0055 - acc: 0.6482 - val_loss: 1.2215 - val_acc: 0.4811\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.9661 - acc: 0.6681 - val_loss: 2.5433 - val_acc: 0.3509\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.9747 - acc: 0.6565 - val_loss: 1.7251 - val_acc: 0.2826\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.9552 - acc: 0.6685 - val_loss: 1.1437 - val_acc: 0.6083\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.9405 - acc: 0.6748 - val_loss: 1.4036 - val_acc: 0.4133\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.9261 - acc: 0.6839 - val_loss: 1.1145 - val_acc: 0.5916\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.9156 - acc: 0.6812 - val_loss: 1.1261 - val_acc: 0.6047\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.9077 - acc: 0.6839 - val_loss: 1.2940 - val_acc: 0.4681\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.8903 - acc: 0.6996 - val_loss: 2.7024 - val_acc: 0.3576\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.9115 - acc: 0.6911 - val_loss: 2.0079 - val_acc: 0.3145\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 0.8906 - acc: 0.7032 - val_loss: 1.1629 - val_acc: 0.6150\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 0.8723 - acc: 0.7030 - val_loss: 1.0675 - val_acc: 0.6087\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.8646 - acc: 0.7049 - val_loss: 1.3233 - val_acc: 0.5768\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.8591 - acc: 0.7117 - val_loss: 1.3499 - val_acc: 0.4290\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.8510 - acc: 0.7164 - val_loss: 1.2301 - val_acc: 0.5413\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.8467 - acc: 0.7151 - val_loss: 1.0446 - val_acc: 0.6312\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.8318 - acc: 0.7249 - val_loss: 1.2672 - val_acc: 0.5292\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 4s 67ms/step - loss: 0.8363 - acc: 0.7177 - val_loss: 1.1878 - val_acc: 0.5845\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.8183 - acc: 0.7284 - val_loss: 1.0744 - val_acc: 0.6173\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.8033 - acc: 0.7354 - val_loss: 1.0685 - val_acc: 0.6132\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.8055 - acc: 0.7352 - val_loss: 1.3353 - val_acc: 0.5494\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 0.8050 - acc: 0.7348 - val_loss: 2.6693 - val_acc: 0.2457\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 0.8170 - acc: 0.7265 - val_loss: 1.4381 - val_acc: 0.4111\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7923 - acc: 0.7372 - val_loss: 1.6115 - val_acc: 0.3203\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7906 - acc: 0.7360 - val_loss: 2.3052 - val_acc: 0.3594\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 4s 67ms/step - loss: 0.8020 - acc: 0.7308 - val_loss: 1.5873 - val_acc: 0.3904\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.7751 - acc: 0.7407 - val_loss: 1.7996 - val_acc: 0.4623\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.7911 - acc: 0.7396 - val_loss: 1.2302 - val_acc: 0.6132\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.7676 - acc: 0.7467 - val_loss: 1.4347 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.7661 - acc: 0.7451 - val_loss: 1.6207 - val_acc: 0.4636\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7621 - acc: 0.7484 - val_loss: 1.6202 - val_acc: 0.6056\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7627 - acc: 0.7537 - val_loss: 1.1677 - val_acc: 0.6119\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.7528 - acc: 0.7535 - val_loss: 1.5379 - val_acc: 0.4057\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7436 - acc: 0.7582 - val_loss: 1.0891 - val_acc: 0.6173\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 0.7348 - acc: 0.7606 - val_loss: 1.4117 - val_acc: 0.4838\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 0.7347 - acc: 0.7646 - val_loss: 1.8770 - val_acc: 0.5876\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 0.7644 - acc: 0.7462 - val_loss: 2.2063 - val_acc: 0.2848\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7389 - acc: 0.7570 - val_loss: 1.0933 - val_acc: 0.6249\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7260 - acc: 0.7599 - val_loss: 1.3673 - val_acc: 0.5539\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 4s 67ms/step - loss: 0.7264 - acc: 0.7625 - val_loss: 2.6713 - val_acc: 0.3607\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7416 - acc: 0.7579 - val_loss: 2.1844 - val_acc: 0.3819\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 0.7380 - acc: 0.7587 - val_loss: 1.3331 - val_acc: 0.6002\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.7149 - acc: 0.7696 - val_loss: 1.5311 - val_acc: 0.5166\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.7095 - acc: 0.7754 - val_loss: 1.5806 - val_acc: 0.5166\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 0.7097 - acc: 0.7667 - val_loss: 2.0143 - val_acc: 0.4124\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 0.7114 - acc: 0.7672 - val_loss: 1.4932 - val_acc: 0.6155\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 1.0446 - acc: 0.6312\n",
      "acc : 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/henrystoll/nlp-split/4f1d035fe2c148d59521d907d51ca5fb\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     test_accuracy             : 0.6311770081520081\n",
      "COMET INFO:     test_loss                 : 1.0446381568908691\n",
      "COMET INFO:     train_acc [53]            : (0.43261075019836426, 0.7754140496253967)\n",
      "COMET INFO:     train_batch_acc [318]     : (0.34375, 0.7791053652763367)\n",
      "COMET INFO:     train_batch_loss [318]    : (0.7070590257644653, 3.8854668140411377)\n",
      "COMET INFO:     train_epoch_duration [53] : (3.613564258965198, 5.891675059974659)\n",
      "COMET INFO:     train_loss [53]           : (0.7094767093658447, 1.9700229167938232)\n",
      "COMET INFO:     train_val_acc [53]        : (0.20934411883354187, 0.6311770081520081)\n",
      "COMET INFO:     train_val_loss [53]       : (1.0446380376815796, 2.70238995552063)\n",
      "COMET INFO:     validate_batch_acc [106]  : (0.2166193127632141, 0.6640625)\n",
      "COMET INFO:     validate_batch_loss [106] : (1.0189625024795532, 2.879389762878418)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     train_trainable_params : 403095\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Nadam_beta_1        : 0.9\n",
      "COMET INFO:     Nadam_beta_2        : 0.999\n",
      "COMET INFO:     Nadam_decay         : 0.004\n",
      "COMET INFO:     Nadam_epsilon       : 1e-07\n",
      "COMET INFO:     Nadam_learning_rate : 0.001\n",
      "COMET INFO:     Optimizer           : Nadam\n",
      "COMET INFO:     activation          : relu\n",
      "COMET INFO:     batch_size          : 128\n",
      "COMET INFO:     bert_model_name     : https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\n",
      "COMET INFO:     dropout             : 0.5\n",
      "COMET INFO:     epochs              : 200\n",
      "COMET INFO:     filters             : 64\n",
      "COMET INFO:     kernel_initializer  : he_normal\n",
      "COMET INFO:     kernel_sizes        : [1, 2, 3]\n",
      "COMET INFO:     l2_lambda           : 0.001\n",
      "COMET INFO:     n_convs_parallel    : 3\n",
      "COMET INFO:     optimizer           : nadam\n",
      "COMET INFO:     padding             : same\n",
      "COMET INFO:     pool_size           : 2\n",
      "COMET INFO:     strides             : 1\n",
      "COMET INFO:     train_Nadam_name    : Nadam\n",
      "COMET INFO:     train_steps         : 59\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     confusion-matrix    : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     histogram3d         : 54\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/henrystoll/nlp-split/ab4c9ac6620b4a1b8b6cec33f2ba2536\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 124,659,587\n",
      "Trainable params: 16,899\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 6s 84ms/step - loss: 1.2689 - acc: 0.4909 - val_loss: 1.1708 - val_acc: 0.5800\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 1.0689 - acc: 0.6231 - val_loss: 1.7439 - val_acc: 0.2758\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.9751 - acc: 0.6752 - val_loss: 1.1566 - val_acc: 0.5490\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 0.9048 - acc: 0.7071 - val_loss: 1.3684 - val_acc: 0.3616\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 0.8567 - acc: 0.7304 - val_loss: 1.2058 - val_acc: 0.4389\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.8096 - acc: 0.7473 - val_loss: 1.7275 - val_acc: 0.2529\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 0.7715 - acc: 0.7702 - val_loss: 1.5614 - val_acc: 0.3598\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 4s 77ms/step - loss: 0.7455 - acc: 0.7747 - val_loss: 1.6062 - val_acc: 0.3059\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.7090 - acc: 0.7933 - val_loss: 1.1653 - val_acc: 0.4789\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.6783 - acc: 0.8073 - val_loss: 1.7491 - val_acc: 0.3589\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.6639 - acc: 0.8127 - val_loss: 1.7264 - val_acc: 0.5728\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.6487 - acc: 0.8228 - val_loss: 2.5810 - val_acc: 0.2925\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.6301 - acc: 0.8266 - val_loss: 1.9151 - val_acc: 0.3872\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.5985 - acc: 0.8402 - val_loss: 1.8897 - val_acc: 0.3450\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 0.5880 - acc: 0.8446 - val_loss: 1.6121 - val_acc: 0.4160\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 0.5621 - acc: 0.8542 - val_loss: 1.9282 - val_acc: 0.3091\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.5628 - acc: 0.8544 - val_loss: 1.6419 - val_acc: 0.4461\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.5380 - acc: 0.8650 - val_loss: 1.9096 - val_acc: 0.4079\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 4s 77ms/step - loss: 0.5268 - acc: 0.8705 - val_loss: 1.3631 - val_acc: 0.4856\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 5s 84ms/step - loss: 0.5133 - acc: 0.8748 - val_loss: 1.7816 - val_acc: 0.5656\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.5167 - acc: 0.8776 - val_loss: 1.4256 - val_acc: 0.4645\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 0.4843 - acc: 0.8876 - val_loss: 1.6664 - val_acc: 0.3949\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.4965 - acc: 0.8834 - val_loss: 1.4622 - val_acc: 0.4591\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 5s 76ms/step - loss: 0.4701 - acc: 0.8899 - val_loss: 1.5712 - val_acc: 0.4659\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.4551 - acc: 0.9005 - val_loss: 2.1247 - val_acc: 0.3953\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.4554 - acc: 0.8952 - val_loss: 1.7308 - val_acc: 0.4429\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.4459 - acc: 0.9005 - val_loss: 2.1436 - val_acc: 0.4070\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.4427 - acc: 0.9006 - val_loss: 1.3885 - val_acc: 0.4793\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 4s 77ms/step - loss: 0.4237 - acc: 0.9098 - val_loss: 1.9335 - val_acc: 0.4245\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 0.4240 - acc: 0.9041 - val_loss: 1.8103 - val_acc: 0.4173\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 0.4119 - acc: 0.9114 - val_loss: 1.3554 - val_acc: 0.4632\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 1.1708 - acc: 0.5800\n",
      "acc : 0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/henrystoll/nlp-split/ab4c9ac6620b4a1b8b6cec33f2ba2536\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     test_accuracy             : 0.5799640417098999\n",
      "COMET INFO:     test_loss                 : 1.1708489656448364\n",
      "COMET INFO:     train_acc [31]            : (0.4909115433692932, 0.9114043116569519)\n",
      "COMET INFO:     train_batch_acc [186]     : (0.3046875, 0.918154776096344)\n",
      "COMET INFO:     train_batch_loss [186]    : (0.4044302999973297, 1.642451286315918)\n",
      "COMET INFO:     train_epoch_duration [31] : (4.328057378006633, 7.4144913359778)\n",
      "COMET INFO:     train_loss [31]           : (0.4118863046169281, 1.268898606300354)\n",
      "COMET INFO:     train_val_acc [31]        : (0.2529200315475464, 0.5799640417098999)\n",
      "COMET INFO:     train_val_loss [31]       : (1.156562089920044, 2.58103346824646)\n",
      "COMET INFO:     validate_batch_acc [62]   : (0.2265625, 0.6328125)\n",
      "COMET INFO:     validate_batch_loss [62]  : (1.1418145895004272, 2.6754534244537354)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     train_trainable_params : 124659587\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Nadam_beta_1        : 0.9\n",
      "COMET INFO:     Nadam_beta_2        : 0.999\n",
      "COMET INFO:     Nadam_decay         : 0.004\n",
      "COMET INFO:     Nadam_epsilon       : 1e-07\n",
      "COMET INFO:     Nadam_learning_rate : 0.001\n",
      "COMET INFO:     Optimizer           : Nadam\n",
      "COMET INFO:     activation          : relu\n",
      "COMET INFO:     batch_size          : 128\n",
      "COMET INFO:     bert_model_name     : https://tfhub.dev/google/nnlm-en-dim128/2\n",
      "COMET INFO:     dropout             : 0.5\n",
      "COMET INFO:     epochs              : 200\n",
      "COMET INFO:     filters             : 64\n",
      "COMET INFO:     kernel_initializer  : he_normal\n",
      "COMET INFO:     kernel_sizes        : [1, 2, 3]\n",
      "COMET INFO:     l2_lambda           : 0.001\n",
      "COMET INFO:     n_convs_parallel    : 3\n",
      "COMET INFO:     optimizer           : nadam\n",
      "COMET INFO:     padding             : same\n",
      "COMET INFO:     pool_size           : 2\n",
      "COMET INFO:     strides             : 1\n",
      "COMET INFO:     train_Nadam_name    : Nadam\n",
      "COMET INFO:     train_steps         : 59\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     confusion-matrix    : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     histogram3d         : 32\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "tfhub_embedding_models = [\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", \"https://tfhub.dev/google/nnlm-en-dim128/2\"]\n",
    "activation = 'relu'\n",
    "kernel_initializer = 'he_normal'\n",
    "l2_lambda = 1e-3\n",
    "dropout=0.5\n",
    "filters = 64\n",
    "kernel_sizes = [1, 2, 3]\n",
    "n_convs_parallel = len(kernel_sizes)\n",
    "padding='same'\n",
    "pool_size = 2\n",
    "strides = 1\n",
    "epochs = 200\n",
    "optimizer = 'nadam'\n",
    "\n",
    "for embed_model in tfhub_embedding_models:\n",
    "    def make_model():\n",
    "        regularizers = keras.regularizers.l2(l2=l2_lambda)\n",
    "        model = keras.Sequential([\n",
    "            hub.KerasLayer(embed_model, dtype=tf.string, input_shape=[],),\n",
    "            keras.layers.Dense(128, activation=activation, kernel_initializer=kernel_initializer, kernel_regularizer=regularizers),\n",
    "            keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
    "        ])\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    project_name = 'nlp_split'\n",
    "    experiment = Experiment(\n",
    "        project_name=project_name,\n",
    "        auto_param_logging=True,\n",
    "        # auto_histogram_weight_logging=True,\n",
    "        auto_histogram_gradient_logging=True,\n",
    "        auto_histogram_activation_logging=True,\n",
    "        api_key=\"HeH9EtfDC2KUlCOjeQaU1CuOM\",\n",
    "        workspace=\"henrystoll\",\n",
    "    )\n",
    "    params = {\n",
    "        'batch_size': batch_size,\n",
    "        'bert_model_name': embed_model,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'pool_size': pool_size,\n",
    "        'padding': padding,\n",
    "        'strides': strides,\n",
    "        'n_convs_parallel': n_convs_parallel,\n",
    "        'activation': activation,\n",
    "        'kernel_initializer': kernel_initializer,\n",
    "        'l2_lambda': l2_lambda,\n",
    "        'dropout': dropout,\n",
    "        'optimizer': optimizer,\n",
    "        'epochs': epochs,\n",
    "    }\n",
    "\n",
    "    experiment.log_parameters(params)\n",
    "\n",
    "    model = make_model()\n",
    "    # keras.utils.plot_model(model, \"model.png\", show_shapes=True)\n",
    "    # experiment.log_asset(\"model.png\")\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=30,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    with experiment.train():\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "    with experiment.test():\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print('acc : {:.3f}'.format(accuracy))\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        experiment.log_metrics(metrics)\n",
    "\n",
    "    y_predicted = model.predict(X_test)\n",
    "    y_predicted = y_predicted.argmax(axis=1)\n",
    "    experiment.log_confusion_matrix(y_test.to_numpy(), y_predicted)\n",
    "\n",
    "    experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
