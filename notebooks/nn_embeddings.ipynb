{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5791,)\n",
      "X_val shape:  (1931,)\n",
      "X_test shape:  (1931,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrystoll/SDK/anaconda3/envs/tensorflow/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP5klEQVR4nO3df6xfdX3H8eeLFkTnD1BuGLZgySRu6DaVBlASnZBBZZswgwan0jmWLhk6TJZN3B9zoiyaTZkyNSGjCoyITNxgxow0iBiNgC0iSDtG549RgrZSfsgMbMX3/vh+6r5Cy+fbes/93nv7fCTf3HPe53zPfd9vgBfnnM/3c1JVSJL0VPabdgOSpPnPsJAkdRkWkqQuw0KS1GVYSJK6lk67gSEccsghtWLFimm3IUkLyoYNG35YVTO72rYow2LFihWsX79+2m1I0oKS5Hu72+ZlKElSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtei/Aa35tZ/nf+r025h3jjiL++YdgvSIDyzkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6ho8LJIsSfKNJJ9v60cmuTnJ5iSfSXJAqz+trW9u21eMHePdrX5XklOG7lmS9LPm4sziXGDT2PoHgQur6oXAA8DZrX428ECrX9j2I8nRwJnAi4FVwMeTLJmDviVJzaBhkWQ58FvAP7T1ACcCn227XAqc3pZPa+u07Se1/U8Drqyqx6rqO8Bm4Ngh+5Yk/ayhzyz+Dvhz4Cdt/XnAg1W1o61vAZa15WXAPQBt+0Nt/5/Wd/Gen0qyJsn6JOu3bds2y3+GJO3bBguLJL8NbK2qDUP9jnFVdXFVrayqlTMzM3PxKyVpn7F0wGOfALwuyanAgcCzgY8AByVZ2s4elgP3tv3vBQ4HtiRZCjwHuH+svtP4eyRJc2CwM4uqendVLa+qFYxuUH+xqt4M3ACc0XZbDVzTlq9t67TtX6yqavUz22ipI4GjgFuG6luS9GRDnlnszruAK5O8H/gGcEmrXwJcnmQzsJ1RwFBVdya5CtgI7ADOqarH575tSdp3zUlYVNWXgC+15W+zi9FMVfUo8IbdvP8C4ILhOpQkPRW/wS1J6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdQ0WFkkOTHJLkm8muTPJe1v9yCQ3J9mc5DNJDmj1p7X1zW37irFjvbvV70pyylA9S5J2bcgzi8eAE6vq14GXAquSHA98ELiwql4IPACc3fY/G3ig1S9s+5HkaOBM4MXAKuDjSZYM2Lck6QkGC4saeaSt7t9eBZwIfLbVLwVOb8untXXa9pOSpNWvrKrHquo7wGbg2KH6liQ92dIhD97OADYALwQ+Bvwn8GBV7Wi7bAGWteVlwD0AVbUjyUPA81r9prHDjr9n/HetAdYAHHHEEd3ejvmzy/b8D1qkNvzNWdNuQdI8N+gN7qp6vKpeCixndDbwywP+rouramVVrZyZmRnq10jSPmlORkNV1YPADcArgIOS7DyjWQ7c25bvBQ4HaNufA9w/Xt/FeyRJc2DI0VAzSQ5qy08HfhPYxCg0zmi7rQauacvXtnXa9i9WVbX6mW201JHAUcAtQ/UtSXqyIe9ZHAZc2u5b7AdcVVWfT7IRuDLJ+4FvAJe0/S8BLk+yGdjOaAQUVXVnkquAjcAO4JyqenzAviVJTzBYWFTV7cDLdlH/NrsYzVRVjwJv2M2xLgAumO0eJUmT8RvckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1UVgkuX6SmiRpcXrKuaGSHAg8AzgkycFA2qZns4sHEEmSFqfeRIJ/BLwTeD6jJ97tDIuHgb8fri1J0nzylGFRVR8BPpLkHVV10Rz1JEmaZyaaoryqLkrySmDF+HuqygdZS9I+YKKwSHI58EvAbcDOBw8VYFhI0j5g0ocfrQSObo85lSTtYyb9nsW3gF8cshFJ0vw16ZnFIcDGJLcAj+0sVtXrBulKkjSvTBoWfzVkE5Kk+W3S0VA3Dt2IJGn+mnQ01I8YjX4COADYH/jvqnr2UI1JkuaPSc8snrVzOUmA04Djh2pKkjS/7PGsszXyL8Aps9+OJGk+mvQy1OvHVvdj9L2LRwfpSJI070w6Gup3xpZ3AN9ldClKkrQPmPSexduGbkSSNH9N+vCj5Un+OcnW9ro6yfKhm5MkzQ+T3uD+JHAto+daPB/411aTJO0DJg2Lmar6ZFXtaK9PATMD9iVJmkcmDYv7k7wlyZL2egtw/5CNSZLmj0nD4g+ANwLfB+4DzgB+f6CeJEnzzKRDZ88HVlfVAwBJngv8LaMQkSQtcpOeWfzazqAAqKrtwMuGaUmSNN9MGhb7JTl450o7s5j0rESStMBN+h/8DwFfS/JPbf0NwAXDtCRJmm8mOrOoqsuA1wM/aK/XV9XlT/WeJIcnuSHJxiR3Jjm31Z+bZF2Su9vPg1s9ST6aZHOS25O8fOxYq9v+dydZvbd/rCRp70x8KamqNgIb9+DYO4A/rapbkzwL2JBkHaNRVNdX1QeSnAecB7wLeC1wVHsdB3wCOK5d8noPo8kLqx3n2vF7KJKkYe3xFOWTqqr7qurWtvwjYBOwjNEEhJe23S4FTm/LpwGXtSnQbwIOSnIYo6nQ11XV9hYQ64BVQ/UtSXqywcJiXJIVjEZP3QwcWlX3tU3fBw5ty8uAe8betqXVdld/4u9Yk2R9kvXbtm2b3T9AkvZxg4dFkmcCVwPvrKqHx7dVVfH/j2v9uVTVxVW1sqpWzsw4E4kkzaZBwyLJ/oyC4oqq+lwr/6BdXqL93Nrq9wKHj719eavtri5JmiODhUV7VvclwKaq+vDYpmuBnSOaVgPXjNXPaqOijgceaperrgNOTnJwGzl1cqtJkubIkF+sOwF4K3BHktta7S+ADwBXJTkb+B6jOacAvgCcCmwGfgy8DUbfFk/yPuDrbb/z2zfIpUXphItOmHYL88ZX3/HVabegZrCwqKqvANnN5pN2sX8B5+zmWGuBtbPXnSRpT8zJaChJ0sJmWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaLCySrE2yNcm3xmrPTbIuyd3t58GtniQfTbI5ye1JXj72ntVt/7uTrB6qX0nS7g15ZvEpYNUTaucB11fVUcD1bR3gtcBR7bUG+ASMwgV4D3AccCzwnp0BI0maO4OFRVV9Gdj+hPJpwKVt+VLg9LH6ZTVyE3BQksOAU4B1VbW9qh4A1vHkAJIkDWyu71kcWlX3teXvA4e25WXAPWP7bWm13dUlSXNoaje4q6qAmq3jJVmTZH2S9du2bZutw0qSmPuw+EG7vET7ubXV7wUOH9tveavtrv4kVXVxVa2sqpUzMzOz3rgk7cvmOiyuBXaOaFoNXDNWP6uNijoeeKhdrroOODnJwe3G9smtJkmaQ0uHOnCSTwO/ARySZAujUU0fAK5KcjbwPeCNbfcvAKcCm4EfA28DqKrtSd4HfL3td35VPfGmuSRpYIOFRVW9aTebTtrFvgWcs5vjrAXWzmJrkqQ95De4JUldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSepaOu0GJGlIN77q1dNuYd549Zdv3Ov3emYhSeoyLCRJXYaFJKnLsJAkdS2YsEiyKsldSTYnOW/a/UjSvmRBhEWSJcDHgNcCRwNvSnL0dLuSpH3HgggL4Fhgc1V9u6r+B7gSOG3KPUnSPiNVNe0eupKcAayqqj9s628Fjquqt4/tswZY01ZfBNw1543uuUOAH067iUXEz3N2+XnOnoXyWb6gqmZ2tWHRfCmvqi4GLp52H3siyfqqWjntPhYLP8/Z5ec5exbDZ7lQLkPdCxw+tr681SRJc2ChhMXXgaOSHJnkAOBM4Nop9yRJ+4wFcRmqqnYkeTtwHbAEWFtVd065rdmwoC6bLQB+nrPLz3P2LPjPckHc4JYkTddCuQwlSZoiw0KS1GVYTInTl8yeJGuTbE3yrWn3stAlOTzJDUk2JrkzybnT7mkhS3JgkluSfLN9nu+ddk97y3sWU9CmL/kP4DeBLYxGe72pqjZOtbEFKsmrgEeAy6rqJdPuZyFLchhwWFXdmuRZwAbgdP/Z3DtJAvxCVT2SZH/gK8C5VXXTlFvbY55ZTIfTl8yiqvoysH3afSwGVXVfVd3aln8EbAKWTberhatGHmmr+7fXgvw/dMNiOpYB94ytb8F/ITXPJFkBvAy4ecqtLGhJliS5DdgKrKuqBfl5GhaSniTJM4GrgXdW1cPT7mchq6rHq+qljGaeODbJgrxUalhMh9OXaN5q19avBq6oqs9Nu5/FoqoeBG4AVk25lb1iWEyH05doXmo3ZC8BNlXVh6fdz0KXZCbJQW356YwGtfz7VJvaS4bFFFTVDmDn9CWbgKsWyfQlU5Hk08DXgBcl2ZLk7Gn3tICdALwVODHJbe116rSbWsAOA25Icjuj/0lcV1Wfn3JPe8Whs5KkLs8sJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIsyDJI53tK/Z0Vtwkn0pyxs/XmTQ7DAtJUpdhIc2iJM9Mcn2SW5PckWR8NuGlSa5IsinJZ5M8o73nmCQ3JtmQ5Lo2Tbg0rxgW0ux6FPjdqno58BrgQ20KDYAXAR+vql8BHgb+uM3DdBFwRlUdA6wFLphC39JTWjrtBqRFJsBftwcy/YTR1POHtm33VNVX2/I/An8C/BvwEmBdy5QlwH1z2rE0AcNCml1vBmaAY6rqf5N8FziwbXvi3DrFKFzurKpXzF2L0p7zMpQ0u54DbG1B8RrgBWPbjkiyMxR+j9EjNu8CZnbWk+yf5MVz2rE0AcNCml1XACuT3AGcxc9OR30XcE6STcDBwCfaY3XPAD6Y5JvAbcAr57Zlqc9ZZyVJXZ5ZSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrv8DULX4RDhptOwAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/tweets_50.csv')\n",
    "X = df['text_tokenized']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)  # 0.8 * 0.25 = 0.2\n",
    "\n",
    "class_names = y.unique().tolist()\n",
    "# print(\"Class names: \", class_names)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_val shape: \", X_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "# TODO: save\n",
    "sns.countplot(y, order=[0, 1, 2, 3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index test:\n",
      "['the', 'cat', 'sat', 'on', 'the', 'mat']  -->  [4, 1170, 2063, 17, 4, 8835]\n"
     ]
    }
   ],
   "source": [
    "HP = {\n",
    "    'batch_size': 128,\n",
    "    'max_tokens':40_000,\n",
    "    'output_sequence_length': 400,\n",
    "}\n",
    "\n",
    "def make_vectorizer(max_tokens: int, output_sequence_length: int) -> TextVectorization:\n",
    "    vect = TextVectorization(max_tokens=max_tokens, output_sequence_length=output_sequence_length)\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(X_train.values).batch(HP.batch_size)\n",
    "    vect.adapt(text_ds)\n",
    "    return vect\n",
    "\n",
    "\n",
    "def get_embedding_matrix(embedding_dim, num_tokens, word_index):\n",
    "    path_to_glove_file = os.path.join(\n",
    "        os.path.expanduser(\"~\"), f\"Documents/Datasets/glove.6B.{embedding_dim}d.txt\"\n",
    "    )\n",
    "    embeddings_index = {}\n",
    "    with open(path_to_glove_file) as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(\"Found {} word vectors.\".format(len(embeddings_index)))\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "    return embedding_matrix\n",
    "\n",
    "def make_embedding_layer(voc: List[str] , embedding_dim:int) -> layers.Embedding:\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "    num_tokens = len(voc) + 2\n",
    "\n",
    "    # just testing if word_index works\n",
    "    test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "    print(\"word_index test:\")\n",
    "    print(test, \" --> \", [word_index[w] for w in test])\n",
    "\n",
    "    embedding_matrix = get_embedding_matrix(embedding_dim, num_tokens, word_index)\n",
    "\n",
    "    return layers.Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "vectorizer = make_vectorizer(max_tokens=HP.max_tokens,\n",
    "                             output_sequence_length=HP.output_sequence_length)\n",
    "vocabulary = vectorizer.get_vocabulary()\n",
    "embedding_layer = make_embedding_layer(vocabulary, embedding_dim=100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_4 (TextVe (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 400, 200)          8000400   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 396, 128)          128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 79, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 75, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 11, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 8,309,652\n",
      "Trainable params: 309,252\n",
      "Non-trainable params: 8,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "    x = vectorizer(string_input)\n",
    "    # int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")(x)\n",
    "    # embedded_sequences = embedding_layer(int_sequences_input)\n",
    "    x = embedding_layer(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=5)(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_ = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "    model = keras.Model(string_input, output_)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_name() -> Tuple[str, str]:\n",
    "    model_name = \"\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = \"logs/\" + model_name + '_' + ts\n",
    "    return model_name, log_dir\n",
    "\n",
    "\n",
    "model_name, log_dir = get_model_name()\n",
    "\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "keras.utils.plot_model(model, f\"img/{model_name}.png\", show_shapes=True)\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# class_weight = {0: 1., 1: 1., 2: 1., 3: 1} # TODO: use?\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=HP.batch_size,\n",
    "                    epochs=200,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    # class_weight=class_weight,\n",
    "                    callbacks=[tensorboard, early_stopping])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}