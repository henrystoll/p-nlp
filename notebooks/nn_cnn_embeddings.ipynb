{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from comet_ml import Experiment\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7603,)\n",
      "X_test shape:  (2050,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('tweets_50_shuffled_train.csv')\n",
    "test_df = pd.read_csv('tweets_50_shuffled_test.csv')\n",
    "X_train = train_df['text_tokenized']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_tokenized']\n",
    "y_test = test_df['label']\n",
    "\n",
    "class_names = y_train.unique()\n",
    "# print(\"Class names: \", class_names)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "# print(\"X_val shape: \", X_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "# TODO: save\n",
    "sns.countplot(x=y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index test:\n",
      "['the', 'cat', 'sat', 'on', 'the', 'mat']  -->  [6, 947, 2152, 19, 6, 7257]\n",
      "Found 400000 word vectors.\n",
      "Converted 18550 words (1450 misses)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_tokens = 20_000\n",
    "output_sequence_length=4000\n",
    "embedding_dim = 300\n",
    "\n",
    "\n",
    "def make_vectorizer(max_tokens: int, output_sequence_length: int) -> TextVectorization:\n",
    "    vect = TextVectorization(max_tokens=max_tokens, output_sequence_length=output_sequence_length)\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(X_train.values).batch(batch_size)\n",
    "    vect.adapt(text_ds)\n",
    "    return vect\n",
    "\n",
    "\n",
    "def get_embedding_matrix(embedding_dim, num_tokens, word_index):\n",
    "    path_to_glove_file = f\"glove.6B.{embedding_dim}d.txt\"\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    with open(path_to_glove_file) as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(\"Found {} word vectors.\".format(len(embeddings_index)))\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def make_embedding_layer(voc: List[str], embedding_dim: int) -> layers.Embedding:\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "    num_tokens = len(voc) + 2\n",
    "\n",
    "    # just testing if word_index works\n",
    "    test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "    print(\"word_index test:\")\n",
    "    print(test, \" --> \", [word_index[w] for w in test])\n",
    "\n",
    "    embedding_matrix = get_embedding_matrix(embedding_dim, num_tokens, word_index)\n",
    "\n",
    "    return layers.Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "        trainable=True,\n",
    "        mask_zero=True\n",
    "    )\n",
    "\n",
    "\n",
    "vectorizer = make_vectorizer(max_tokens=max_tokens,\n",
    "                             output_sequence_length=output_sequence_length)\n",
    "vocabulary = vectorizer.get_vocabulary()\n",
    "embedding_layer = make_embedding_layer(vocabulary, embedding_dim=embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "optimizer = 'nadam'\n",
    "activation = 'relu'\n",
    "kernel_initializer = 'he_normal'\n",
    "l2_lambda = 1e-3\n",
    "dropout=0.5\n",
    "filters = 128\n",
    "n_convs_depth = 1\n",
    "# kernel_size = 3\n",
    "kernel_sizes = [1, 2, 3]\n",
    "n_convs_parallel = len(kernel_sizes)\n",
    "padding='same'\n",
    "pool_size = 3\n",
    "# pool_size = 5\n",
    "strides = 1\n",
    "# strides = 2\n",
    "class_weight = None\n",
    "embedding='mask & trainable'\n",
    "\n",
    "def make_model():\n",
    "    regularizers = keras.regularizers.l2(l2=l2_lambda)\n",
    "    convs = []\n",
    "    string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "    x = vectorizer(string_input)\n",
    "    embed = embedding_layer(x)\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # for _ in range(n_convs_depth):\n",
    "        x = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation=activation,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            kernel_regularizer=regularizers,\n",
    "            padding=padding,\n",
    "        )(embed)\n",
    "        x = layers.SpatialDropout1D(dropout)(x)\n",
    "        x = layers.MaxPooling1D(pool_size=pool_size, strides=strides)(x)\n",
    "        convs.append(layers.GlobalMaxPooling1D()(x))\n",
    "\n",
    "    x = layers.Concatenate()(convs)\n",
    "    x = layers.Dense(n_convs_parallel*filters, activation=activation, kernel_regularizer=regularizers)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    output_ = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "    model = keras.Model(string_input, output_)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/henrystoll/nlp-split/eddff4be69be416a8d82dc922c6f3a68\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 4000)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 4000, 300)    6000600     text_vectorization[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4000, 128)    38528       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4000, 128)    76928       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4000, 128)    115328      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 4000, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 4000, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 4000, 128)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3998, 128)    0           spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 3998, 128)    0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 3998, 128)    0           spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 384)          147840      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 384)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            1155        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,380,379\n",
      "Trainable params: 6,380,379\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 133s 2s/step - loss: 2.5199 - acc: 0.3895 - val_loss: 2.1158 - val_acc: 0.4220\n",
      "Epoch 2/200\n",
      "17/60 [=======>......................] - ETA: 1:30 - loss: 2.1147 - acc: 0.4256"
     ]
    }
   ],
   "source": [
    "project_name = 'nlp_split'\n",
    "experiment = Experiment(\n",
    "    project_name=project_name,\n",
    "    auto_param_logging=True,\n",
    "    # auto_histogram_weight_logging=True,\n",
    "    auto_histogram_gradient_logging=True,\n",
    "    auto_histogram_activation_logging=True,\n",
    "    api_key=\"HeH9EtfDC2KUlCOjeQaU1CuOM\",\n",
    "    workspace=\"henrystoll\",\n",
    ")\n",
    "params = {\n",
    "    'batch_size': batch_size,\n",
    "    'max_tokens': max_tokens,\n",
    "    'output_sequence_length': output_sequence_length,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'embedding': embedding,\n",
    "    'filters': filters,\n",
    "    'kernel_sizes': kernel_sizes,\n",
    "    'pool_size': pool_size,\n",
    "    'padding': padding,\n",
    "    'strides': strides,\n",
    "    'n_convs_depth': n_convs_depth,\n",
    "    'n_convs_parallel': n_convs_parallel,\n",
    "    'activation': activation,\n",
    "    'kernel_initializer': kernel_initializer,\n",
    "    'l2_lambda': l2_lambda,\n",
    "    'dropout': dropout,\n",
    "    'class_weight': class_weight,\n",
    "    'optimizer': optimizer,\n",
    "    'epochs': epochs,\n",
    "}\n",
    "\n",
    "experiment.log_parameters(params)\n",
    "\n",
    "model = make_model()\n",
    "# keras.utils.plot_model(model, \"model.png\", show_shapes=True)\n",
    "# experiment.log_asset(\"model.png\")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "with experiment.train():\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        class_weight=class_weight,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "with experiment.test():\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('acc : {:.3f}'.format(accuracy))\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    experiment.log_metrics(metrics)\n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.argmax(axis=1)\n",
    "experiment.log_confusion_matrix(y_test.to_numpy(), y_predicted)\n",
    "\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}